# ğŸ›’ Automated Price Tracking System

A production-style backend system that tracks product prices over time using browser automation, scheduled jobs, and time-series data storage.

This project focuses on **real-world backend engineering practices**, not just basic scraping.

---

## ğŸš€ What This Project Does

- Accepts product URLs from users
- Scrapes live product data using browser automation
- Stores immutable price history (time-series data)
- Automatically re-scrapes products daily using cron jobs
- Exposes APIs to fetch:
  - Todayâ€™s price
  - Yesterdayâ€™s price
  - Price change
- Built with scalability, reliability, and debuggability in mind

---

## ğŸ§  Production-Level Engineering Approach

### 1ï¸âƒ£ Separation of Static vs Dynamic Data

- **Product data** (URL, title, image) is stored once
- **History data** stores only time-variant fields like price and availability
- Avoids duplication and ensures consistency across historical records

This mirrors how production systems handle **master data vs time-series data**.

---

### 2ï¸âƒ£ Immutable Price History

- Each scrape creates a **new database record**
- Historical data is never overwritten
- Enables accurate:
  - Daily comparisons
  - Price trend analysis

This approach is common in **financial and monitoring systems**.

---

### 3ï¸âƒ£ Safe Date-Based Queries

- Uses **date-range filtering** instead of relying on record order
- Prevents incorrect results caused by:
  - Missed cron runs
  - Multiple scrapes in a single day
- Timezone-aware logic ensures consistent results

---

### 4ï¸âƒ£ Automated Background Jobs (Cron)

- Daily scraping is handled via scheduled background jobs
- Cron runs independently of user requests
- Ensures data freshness without manual triggers

This pattern is widely used in production for **periodic data syncs**.

---

### 5ï¸âƒ£ Controlled Scraping Strategy

- Products are processed sequentially to avoid IP blocking
- Designed to support:
  - Rate limiting
  - Delays between requests
  - Future queue-based processing if scale increases

---

### 6ï¸âƒ£ Clean Error Handling & Debugging

- Failures during scraping do not crash the system
- Each step is logged for easy debugging
- Partial failures do not block the entire job

---

## ğŸ›  Tech Stack

- **Node.js** â€“ Backend runtime
- **Express.js** â€“ API layer
- **Playwright** â€“ Browser automation & scraping
- **MongoDB + Mongoose** â€“ Data persistence
- **node-cron** â€“ Scheduled background jobs

---

## ğŸ“Š Example Use Cases

- Price tracking & alerts
- Market monitoring tools
- E-commerce analytics
- Historical pricing dashboards


## ğŸ“Œ Future Enhancements

- Authentication & user-specific tracking
- Price alerts and notifications
- Aggregation pipelines for analytics
- Queue-based scraping (BullMQ / Redis)
- Cloud deployment & monitoring

---

## ğŸ§‘â€ğŸ’» Author

Built as a hands-on project to practice **production-grade backend engineering** concepts.
